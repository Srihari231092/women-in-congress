{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Part-3:-Train-bigram-and-trigram-models-and-use-them-on-all-speeches\" data-toc-modified-id=\"Part-3:-Train-bigram-and-trigram-models-and-use-them-on-all-speeches-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Part 3: Train bigram and trigram models and use them on all speeches</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#We-use-SpaCy-to-tokenize-and-POS-tag-each-speech\" data-toc-modified-id=\"We-use-SpaCy-to-tokenize-and-POS-tag-each-speech-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>We use SpaCy to tokenize and POS tag each speech</a></span></li><li><span><a href=\"#Lazy-load-the-speeches\" data-toc-modified-id=\"Lazy-load-the-speeches-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Lazy load the speeches</a></span></li><li><span><a href=\"#Save-speeches-alone-to-a-text-file-to-speed-up-processing\" data-toc-modified-id=\"Save-speeches-alone-to-a-text-file-to-speed-up-processing-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Save speeches alone to a text file to speed up processing</a></span></li><li><span><a href=\"#Create-a-bunch-of-helper-functions-to-help-us-read-speeches-from-the-file,-remove-punctuation-and-whitespace-and-lemmatize-words\" data-toc-modified-id=\"Create-a-bunch-of-helper-functions-to-help-us-read-speeches-from-the-file,-remove-punctuation-and-whitespace-and-lemmatize-words-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Create a bunch of helper functions to help us read speeches from the file, remove punctuation and whitespace and lemmatize words</a></span></li><li><span><a href=\"#Lemmatize-all-words-in-speeches-and-store-them-in-text-file-to-save-memory\" data-toc-modified-id=\"Lemmatize-all-words-in-speeches-and-store-them-in-text-file-to-save-memory-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Lemmatize all words in speeches and store them in text file to save memory</a></span></li><li><span><a href=\"#Learn-bigrams-in-speeches-and-save-model-to-disk\" data-toc-modified-id=\"Learn-bigrams-in-speeches-and-save-model-to-disk-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>Learn bigrams in speeches and save model to disk</a></span></li><li><span><a href=\"#Identify-bigrams-in-the-speeches-and-save-in-txt-file\" data-toc-modified-id=\"Identify-bigrams-in-the-speeches-and-save-in-txt-file-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>Identify bigrams in the speeches and save in txt file</a></span></li><li><span><a href=\"#Learn-trigrams-in-speeches-and-save-model-to-disk\" data-toc-modified-id=\"Learn-trigrams-in-speeches-and-save-model-to-disk-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>Learn trigrams in speeches and save model to disk</a></span></li><li><span><a href=\"#Identify-trigrams-in-the-speeches-and-save-in-txt-file\" data-toc-modified-id=\"Identify-trigrams-in-the-speeches-and-save-in-txt-file-1.0.9\"><span class=\"toc-item-num\">1.0.9&nbsp;&nbsp;</span>Identify trigrams in the speeches and save in txt file</a></span></li><li><span><a href=\"#Now-process-all-speeches-from-plain-text-to-unigram-(lemmatized),-bigram-and-finally-trigram-representation\" data-toc-modified-id=\"Now-process-all-speeches-from-plain-text-to-unigram-(lemmatized),-bigram-and-finally-trigram-representation-1.0.10\"><span class=\"toc-item-num\">1.0.10&nbsp;&nbsp;</span>Now process all speeches from plain text to unigram (lemmatized), bigram and finally trigram representation</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyse all house of commons speeches since 1970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Part 1: Get a list of MPs and their affiliations](MP_speeches-Part1.ipynb)\n",
    "\n",
    "[Part 2: Download all speeches belonging to MPs in list](MP_speeches-Part2.ipynb)\n",
    "\n",
    "## Part 3: Train bigram and trigram models and use them on all speeches\n",
    "\n",
    "[Part 4: Train an LDA topic model and process all speeches with it](MP_speeches-Part4.ipynb)\n",
    "\n",
    "[Part 5: Analyse the results of the LDA model](MP_speeches-Part5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bigrams (Trigrams) are any two (three) words that often go together.\n",
    "For example, Maastricht treaty (House of Commons) would be converted to maastricht_treaty (house_of_commons) with such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bcolz\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import codecs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    if os.path.isfile(\"raw_speeches.h5\"):\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### We use SpaCy to tokenize and POS tag each speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Load english language model from spacy\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en\")\n",
    "    # If it complains, you may need to downgrade pip: pip install pip==9.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Directory to store Phrase models\n",
    "from config import INTERMEDIATE_DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Lazy load the speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "speeches = bcolz.open(\"speeches.bcolz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Save speeches alone to a text file to speed up processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p $INTERMEDIATE_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save speeches to txt file first to make it quicker to process in batches with lower memory\n",
    "speeches_filepath = os.path.join(INTERMEDIATE_DIRECTORY, \"speeches.txt\")\n",
    "# Set to True if you want to run this again\n",
    "if False:\n",
    "    with codecs.open(speeches_filepath, \"w\", encoding=\"utf_8\") as f:\n",
    "        for speech in speeches[\"body\"]:\n",
    "            f.write(speech + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Create a bunch of helper functions to help us read speeches from the file, remove punctuation and whitespace and lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#%%writefile helper_functions.py\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_speech(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in speeches from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for speech in f:\n",
    "            yield speech.replace('\\\\n', '\\n')\n",
    "\n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse speeches,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_speech in nlp.pipe(line_speech(filename),\n",
    "                                  batch_size=10000, n_threads=8):\n",
    "        \n",
    "        for sent in parsed_speech.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Lemmatize all words in speeches and store them in text file to save memory\n",
    "Lemmatization is the process of stripping word endings to convert words to their stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 16.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is a bit time consuming (takes about 1h) - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "unigram_sentences_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'unigram_sentences_all.txt')\n",
    "if False:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus(speeches_filepath):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zora 's writing and -PRON- work as a teacher hollywood scriptwriter and a newspaper columnist be all instrumental in -PRON- contribution to the american literary landscape\r\n",
      "-PRON- be zora 's literary accomplishment -PRON- style of writing and the subject of the african- american experience that be indispensable in -PRON- major influence on such great contemporary female poet and author such as toni morrison maya angelou and alice walker\r\n",
      "after zora 's death in 1960 the popularity of -PRON- writing increase\r\n",
      "today zora 's name be highlight in the black female playwrights category and -PRON- have be induct into the women 's hall of fame and florida 's writer 's hall of fame\r\n",
      "as a woman a minority and a former english teacher -PRON- pay tribute to zora neale hurston for all of -PRON- achievement and for put woman 's literary accomplishment on the map\r\n",
      "-PRON- be not the only one to applaud zora for all that -PRON- achieve for -PRON- writing have also be instrumental in inspire the zora neale hurston festival which have boast an attendance rate of 60,000 in the past and be expect to grow to a rate of 100,000 this year\r\n",
      "past attendee have include literary great and pulitzer prize winner alice walker in addition to other international visitor from as far as new zealand japan italy and australia\r\n",
      "zora neale hurston -PRON- applaud -PRON- for -PRON- commitment and dedication to literature and for -PRON- influence on some of america 's future great writer\r\n",
      "the boy and girl who be so proud to attend the school that bear -PRON- name join -PRON- in spirit in celebrate -PRON- legacy\r\n",
      "and -PRON- thank -PRON- dear florida colleague corrine brown\r\n"
     ]
    }
   ],
   "source": [
    "!tail intermediate/unigram_sentences_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Learn bigrams in speeches and save model to disk\n",
    "Bigrams are any two words that often go together. For example, Maastricht treaty would be converted to maastricht_treaty with such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 836 ms, total: 1min 29s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "bigram_model_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'bigram_model_all')\n",
    "if False:\n",
    "    # Open unigram sentences as a stream\n",
    "    unigram_sentences = LineSentence(unigram_sentences_filepath)\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "else:\n",
    "    # load the finished model from disk\n",
    "    bigram_model = Phrases.load(bigram_model_filepath)\n",
    "# Phraser class is much faster than Phrases\n",
    "bigram_phraser = Phraser(bigram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Identify bigrams in the speeches and save in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 16.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this is a bit time consuming (takes about 20 mins) - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "bigram_sentences_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'bigram_sentences_all.txt')\n",
    "if False:\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f: \n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            bigram_sentence = u' '.join(bigram_model[unigram_sentence])\n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zora 's writing and -PRON- work as a teacher hollywood scriptwriter and a newspaper_columnist be all instrumental in -PRON- contribution to the american literary landscape\r\n",
      "-PRON- be zora 's literary accomplishment -PRON- style of writing and the subject of the african-_american experience that be indispensable in -PRON- major influence on such great contemporary female poet and author such as toni_morrison maya_angelou and alice_walker\r\n",
      "after zora 's death in 1960 the popularity of -PRON- writing increase\r\n",
      "today zora 's name be highlight in the black female playwrights category and -PRON- have be induct_into the women 's hall of fame and florida 's writer 's hall of fame\r\n",
      "as a woman a minority and a former english teacher -PRON- pay_tribute to zora_neale hurston for all of -PRON- achievement and for put woman 's literary accomplishment on the map\r\n",
      "-PRON- be not the only one to applaud zora for all that -PRON- achieve for -PRON- writing have also be instrumental in inspire the zora_neale hurston festival which have boast an attendance rate of 60,000 in the past and be expect to grow to a rate of 100,000 this year\r\n",
      "past attendee have include literary great and pulitzer_prize winner alice_walker in addition to other international visitor from as far as new_zealand japan italy and australia\r\n",
      "zora_neale hurston -PRON- applaud -PRON- for -PRON- commitment and dedication to literature and for -PRON- influence on some of america 's future great writer\r\n",
      "the boy and girl who be so proud to attend the school that bear -PRON- name join -PRON- in spirit in celebrate -PRON- legacy\r\n",
      "and -PRON- thank -PRON- dear florida colleague corrine_brown\r\n"
     ]
    }
   ],
   "source": [
    "!tail intermediate/bigram_sentences_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Learn trigrams in speeches and save model to disk\n",
    "Trigrams are any three words that often go together. For example, House of Commons would be converted to house_of_commons with such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 1.7 s, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Learn a trigram model from bigrammed speeches\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "trigram_model_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'trigram_model_all')\n",
    "if False:\n",
    "    # Open bigram sentences as a stream\n",
    "    bigram_sentences = LineSentence(bigram_sentences_filepath)\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "else:\n",
    "    # load the finished model from disk\n",
    "    trigram_model = Phrases.load(trigram_model_filepath)\n",
    "trigram_phraser = Phraser(trigram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Identify trigrams in the speeches and save in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 28.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Save speeches as trigrams in txt file\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "trigram_sentences_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'trigram_sentences_all.txt')\n",
    "if False:\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            trigram_sentence = u' '.join(trigram_model[bigram_sentence])\n",
    "            f.write(trigram_sentence + '\\n')\n",
    "# Open trigrams file as stream\n",
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zora 's writing and -PRON- work as a teacher hollywood scriptwriter and a newspaper_columnist be all instrumental in -PRON- contribution to the american literary landscape\r\n",
      "-PRON- be zora 's literary accomplishment -PRON- style of writing and the subject of the african-_american experience that be indispensable in -PRON- major influence on such great contemporary female poet and author such as toni_morrison maya_angelou and alice_walker\r\n",
      "after zora 's death in 1960 the popularity of -PRON- writing increase\r\n",
      "today zora 's name be highlight in the black female playwrights category and -PRON- have be induct_into the women 's hall of fame and florida 's writer 's hall of fame\r\n",
      "as a woman a minority and a former english teacher -PRON- pay_tribute to zora_neale_hurston for all of -PRON- achievement and for put woman 's literary accomplishment on the map\r\n",
      "-PRON- be not the only one to applaud zora for all that -PRON- achieve for -PRON- writing have also be instrumental in inspire the zora_neale_hurston festival which have boast an attendance rate of 60,000 in the past and be expect to grow to a rate of 100,000 this year\r\n",
      "past attendee have include literary great and pulitzer_prize_winner alice_walker in addition to other international visitor from as far as new_zealand japan italy and australia\r\n",
      "zora_neale_hurston -PRON- applaud -PRON- for -PRON- commitment and dedication to literature and for -PRON- influence on some of america 's future great writer\r\n",
      "the boy and girl who be so proud to attend the school that bear -PRON- name join -PRON- in spirit in celebrate -PRON- legacy\r\n",
      "and -PRON- thank -PRON- dear florida colleague corrine_brown\r\n"
     ]
    }
   ],
   "source": [
    "!tail intermediate/trigram_sentences_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Now process all speeches from plain text to unigram (lemmatized), bigram and finally trigram representation\n",
    "We previously learned the unigram, bigram and trigram models. Now we need to apply it to all the speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load last names and pronouns into stopwords so that they are filtered out\n",
    "from spacy.en.language_data import STOP_WORDS\n",
    "\n",
    "for word in [\"mr.\", \"mrs.\", \"ms.\", \"``\", \"sir\", \"madam\", \"gentleman\", \"colleague\", \"gentlewoman\", \"speaker\", \"-PRON-\"] + list(pd.read_hdf(\"list_of_members.h5\", \"members\").last_name.str.lower().unique()):\n",
    "    STOP_WORDS.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_text(parsed_speech):\n",
    "   # lemmatize the text, removing punctuation and whitespace\n",
    "    unigram_speech = [token.lemma_ for token in parsed_speech\n",
    "                      if not punct_space(token)]\n",
    "\n",
    "    # remove any remaining stopwords\n",
    "    unigram_speech = [term for term in unigram_speech\n",
    "                      if term not in STOP_WORDS]\n",
    "    \n",
    "    # apply the bigram and trigram phrase models\n",
    "    bigram_speech = bigram_phraser[unigram_speech]\n",
    "    trigram_speech = trigram_phraser[bigram_speech]\n",
    "\n",
    "    # write the transformed speech as a line in the new file\n",
    "    trigram_speech = u' '.join(trigram_speech) \n",
    "    \n",
    "    return trigram_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulate maryland tennessee michigan hard work legislation assistance support york chairman effort bring bill floor timely piece legislation urge support bill reserve balance time texas yield time consume tennessee rank_member subcommittee environment technology standards legislation begin write electronic_authentication provision rank_member subcommittee aeronautics texas request time yield balance time'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(nlp(\"I congratulate the gentlewoman from Maryland (Mrs. Morella), the  gentleman from Tennessee (Mr. Gordon), and the gentleman from Michigan  (Mr. Barcia) for their hard work on this legislation. Also, we would  not be here without the assistance and support of the gentleman from  New York (Chairman Boehlert) and his efforts to bring this bill to the  floor. This a timely piece of legislation, Madam Speaker, and I would  urge my colleagues to support the bill.   Madam Speaker, I reserve the balance of my time.   Mr. HALL of Texas. Madam Speaker, I yield such time as he may consume  to the gentleman from Tennessee (Mr. Gordon), who was ranking member on  the Subcommittee on Environment, Technology, and Standards back when  this legislation first began and wrote the electronic authentication  provisions in it. He is now ranking member on the Subcommittee on Space  and Aeronautics.   Mr. HALL of Texas. Madam Speaker, I have no further requests for  time, and I yield back the balance of my time.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 1min 18s, sys: 9.39 s, total: 4h 1min 28s\n",
      "Wall time: 1h 33min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming (takes about 2h) - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "trigram_speeches_filepath = os.path.join(INTERMEDIATE_DIRECTORY, 'trigram_transformed_speeches_all.txt')\n",
    "if True:\n",
    "    with codecs.open(trigram_speeches_filepath, 'w', encoding='utf_8') as f:  \n",
    "        for parsed_speech in nlp.pipe(line_speech(speeches_filepath),\n",
    "                                      batch_size=10000, n_threads=4):\n",
    "            f.write(clean_text(parsed_speech) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rise support california loretta duly_elect 46th_district california 10 month ago certify republican secretary state 10 month ago important bring close committee house oversight hear special session evidence close california win 900 vote plurality duly_elect let bring close let serve people district work american people\r\n",
      "ros_lehtinen rise honor african-_american 's influential significant voice 20th_century zora_neale_hurston zora renowned distinguished writer interpreter southern african_american culture serve today 40 year death experienced role_model woman nation work contribution american culture literature fit commemorative_stamp recognize zora 's contribution american life beautiful elementary_school congressional_district gifted_artist privilege speak boy girl talented teacher staff daily work play learn zora_neale_hurston come age literature time woman recently right vote recognition female literary writer especially african_american woman unheard zora 's success ability overcome odd like congratulate congresswoman_corrine jacksonville spearhead congressional effort stamp issue zora zora grow eatonville_fl town approximately 10 mile orlando settle newly slave daughter tenant farmer later eatonville 's mayor great lady 's schooling constantly interrupt maintain natural_curiosity sharpen creative ability constant reading formal education zora insure place literary history finish high_school work waitress enrol university encourage write alain locke african_american leader professor zora 's determination commitment literature honor story drenched light publish 1924 edition opportunity magazine publish urban_league publication story eventually result scholarship college columbia university interest anthropology specifically folklore harlem american celebrate zora choose victor urban_league 's literary contest story one- act play category recognition fundamental associate great artist poet include langston zora 's writing work teacher hollywood scriptwriter newspaper_columnist instrumental contribution american literary landscape zora 's literary accomplishment style writing subject african-_american experience indispensable influence great contemporary female poet author toni maya_angelou alice zora 's death 1960 popularity writing increase today zora 's highlight female playwrights category induct women 's fame florida 's writer 's fame woman minority teacher pay_tribute zora_neale_hurston achievement woman 's literary accomplishment map applaud zora achieve writing instrumental inspire zora_neale_hurston festival boast attendance rate 60,000 past expect grow rate 100,000 year past attendee include literary great pulitzer_prize_winner alice addition international visitor far zealand japan italy australia zora_neale_hurston applaud commitment dedication literature influence america 's future great writer boy girl proud attend school bear join spirit celebrate legacy thank florida corrine\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 intermediate/trigram_transformed_speeches_all.txt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "46px",
    "left": "924px",
    "right": "20px",
    "top": "53.6979px",
    "width": "600px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
