{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Analyse all house of commons speeches since 1970"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[Part 1: Get a list of MPs and their affiliations](MP_speeches-Part1.ipynb)\n",
    "\n",
    "## Part 2: Download all speeches belonging to MPs in list\n",
    "\n",
    "[Part 3: Train bigram and trigram models and use them on all speeches](MP_speeches-Part3.ipynb)\n",
    "\n",
    "[Part 4: Train an LDA topic model and process all speeches with it](MP_speeches-Part4.ipynb)\n",
    "\n",
    "[Part 5: Analyse the results of the LDA model](MP_speeches-Part5.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the list of MPs from Part 1\n",
    "mps = pd.read_hdf(\"list_of_mps.h5\", \"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use TheyWorkForYou's API to download all the speeches of a particular MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_mp_speeches(mp_id):\n",
    "    \"\"\"Get all speeches of a particular MP from the TheyWorkForYou API as save them to a csv file under speeches/\"\"\"\n",
    "    \n",
    "    # Store TheyWorkForYou API key in separate config file\n",
    "    from config import TWFY_API_KEY\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    \"\"\"Get speeches of a particular MP based on TheyWorkForYou id and convert data into long format pandas data frame.\n",
    "    Each row represents one speech at a particular date and time\"\"\"\n",
    "    all_speeches = pd.DataFrame()\n",
    "    rows = [1]\n",
    "    page_no=1\n",
    "    while len(rows) > 0:\n",
    "        t = requests.get(\"https://www.theyworkforyou.com/api/getDebates?key={api_key}&\\\n",
    "                     type=commons&person={person}&results_per_page=1000&num={num}&page={page}&output=js\".format(api_key=TWFY_API_KEY,\n",
    "                                                                                                               person=mp_id,\n",
    "                                                                                                               num=1000,\n",
    "                                                                                                               page=page_no))\n",
    "        rows = t.json()[\"rows\"]\n",
    "        speeches = []\n",
    "        # Loop over each row\n",
    "        for row in rows:\n",
    "            speeches.append({\n",
    "                    'speech_id':row[\"gid\"],\n",
    "                    'speech_url':row[\"listurl\"],\n",
    "                    'mp_name':row[\"speaker\"][\"name\"],\n",
    "                    'mp_constituency':row[\"speaker\"][\"constituency\"],\n",
    "                    'mp_party':row[\"speaker\"][\"party\"],\n",
    "                    'mp_id':row[\"person_id\"],\n",
    "                    'date':pd.to_datetime(row[\"hdate\"], format=\"%Y-%m-%d\"),\n",
    "                    'time':row[\"htime\"],\n",
    "                    'section_id':row[\"section_id\"],\n",
    "                    'subsection_id':row[\"subsection_id\"],\n",
    "                    'debate_title':row[\"parent\"][\"body\"],\n",
    "                    'body':BeautifulSoup(row[\"body\"], \"html5lib\").get_text()\n",
    "                })\n",
    "        speeches = pd.DataFrame(speeches)\n",
    "\n",
    "        # Concatenate onto complete speeches dataframe\n",
    "        all_speeches = pd.concat([all_speeches, speeches], ignore_index=True)\n",
    "        # Increment page_counter\n",
    "        page_no += 1\n",
    "    \n",
    "    print(\"Got speeches for MP {0}\".format(mp_id))\n",
    "    # Write to new hdf file specifically for mp\n",
    "    all_speeches.to_csv(\"speeches/mp-{0}.csv\".format(mp_id), index=False)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the above function in parallel for all MPs in the list that do not have a speeches file yet\n",
    "This will take a while (~15 mins, depending on your internet connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got speeches for MP 10002\n",
      "Got speeches for MP 13825\n",
      "Got speeches for MP 13893\n",
      "Got speeches for MP 25604\n",
      "Got speeches for MP 11734\n",
      "Got speeches for MP 13836\n",
      "Got speeches for MP 13904\n",
      "Got speeches for MP 25154\n",
      "Got speeches for MP 17908\n",
      "Got speeches for MP 25636\n",
      "Got speeches for MP 10913\n",
      "Got speeches for MP 10858\n",
      "Got speeches for MP 10387\n",
      "CPU times: user 432 ms, sys: 724 ms, total: 1.16 s\n",
      "Wall time: 2.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Download all MP speeches if this is set to True\n",
    "## This can take a while\n",
    "if False:\n",
    "    # Figure out which MPs we still need to download\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    downloaded_mps = [int(file.split(\"/\")[-1].split(\".\")[0].split(\"-\")[1]) for file in glob.glob(\"./speeches/mp-*.csv\")]\n",
    "    mps_to_download = [mp for mp in list(mps.index) if mp not in downloaded_mps]\n",
    "    # Parallelise downloading of MP speeches\n",
    "    from multiprocessing import Pool\n",
    "\n",
    "    # Number of threads to use to fetch\n",
    "    NUM_THREADS = 16\n",
    "    # Make list of mp ids\n",
    "    list_of_mp_ids = mps_to_download\n",
    "    #list_of_mp_ids = list(mps.query(\"exists==False\")[\"Person ID\"])[:10]\n",
    "\n",
    "    # Create pool of threads\n",
    "    pool = Pool(NUM_THREADS)\n",
    "    # Use pool.map to download speeches mp by mp\n",
    "    results = pool.map(get_mp_speeches, list_of_mp_ids)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Remove the empty mp files\n",
    "    import glob\n",
    "    import os\n",
    "    for file in glob.glob(\"./speeches/mp-*.csv\"):\n",
    "        if os.path.getsize(file) == 1:\n",
    "            os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
